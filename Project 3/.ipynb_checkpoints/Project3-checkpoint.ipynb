{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "37d1vFe2bZeU"
   },
   "source": [
    "# Deep Neural Network Project 51: Coins Classification using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7406,
     "status": "ok",
     "timestamp": 1545835307046,
     "user": {
      "displayName": "Manuel Ruiz",
      "photoUrl": "",
      "userId": "18393208488880897713"
     },
     "user_tz": -60
    },
    "id": "Hlo3WvpobZec",
    "outputId": "e8c010c8-f7db-4f15-9e50-c5679011d521"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import the librarys that will be use\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# Used for plotting and display of figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import keras\n",
    "from __future__ import print_function\n",
    "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape, GlobalMaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dropout\n",
    "from keras.models import model_from_yaml\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers \n",
    "import keras.backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wJUxWZTtjOLE"
   },
   "source": [
    "## First Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28219,
     "status": "ok",
     "timestamp": 1545823183827,
     "user": {
      "displayName": "Manuel Ruiz",
      "photoUrl": "",
      "userId": "18393208488880897713"
     },
     "user_tz": -60
    },
    "id": "YInN97s5GMNc",
    "outputId": "d905c288-4181-4bef-c30c-35484a4dbc8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "#Monuting drive on Colaboratory envyroment\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lcR1404rHQtp"
   },
   "outputs": [],
   "source": [
    "#Path used for read images from drive\n",
    "path1=\"gdrive/My Drive/UNI/2018-2019/MLNN/Project 3/Dataset1/\"\n",
    "path2=\"gdrive/My Drive/UNI/2018-2019/MLNN/Project 3/Dataset2/\"\n",
    "#Path will be use for read images at your filesystem\n",
    "path3=\"Dataset1/\"\n",
    "path4=\"Dataset2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "biIQWk4ZbZfI"
   },
   "outputs": [],
   "source": [
    "#Set imagen size for resize images\n",
    "imageSize = 128\n",
    "\n",
    "#Function that read the images from the folder and transform them in np.arrays\n",
    "def save(path):\n",
    "\t#Load, normalize and reshape\n",
    "    files = os.listdir(path)\n",
    "    files = [file for file in files if file.endswith(\".png\")]\n",
    "  \n",
    "    X = []\n",
    "    for i, file in enumerate(files):\n",
    "    \t#print \"Adding file {}/{}\".format(i,len(files))\n",
    "        img = cv2.imread(path+file, -1)\n",
    "\n",
    "        # Convert grayscale to RGB\n",
    "        if len(img.shape) == 2:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        #gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        #sift = cv2.xfeatures2d.SIFT_create()\n",
    "        #kp, des = sift.detectAndCompute(gray,None)\n",
    "\n",
    "        # Resize to desired size and normalize\n",
    "        img = cv2.resize(img,(imageSize,imageSize))\n",
    "        img = img.astype(float)/255.\n",
    "        X.append(img)\n",
    "        \n",
    "\n",
    "    # Convert to numpy array\n",
    "    X = np.array(X)\n",
    "    return X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OaULX4SpbZfb"
   },
   "outputs": [],
   "source": [
    "#Reading Roman coins images from drive. It works only on Colaboratory enviroment that have mounted the drive account\n",
    "# that have stored the dataset.\n",
    "Dataset1=save(path1) \n",
    "Labels1=np.zeros(Dataset1.shape[0]) # Labels for Roman images: class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cIjj7d7uLxgv"
   },
   "outputs": [],
   "source": [
    "#Reading Roman coins images from file system\n",
    "Dataset1=save(path3) \n",
    "Labels1=np.zeros(Dataset1.shape[0])  # Labels for Roman images: class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zKSzKxSkbZfj"
   },
   "outputs": [],
   "source": [
    "#Reading other coins images from drive. It works only on Colaboratory enviroment that have mounted the drive account\n",
    "# that have stored the dataset.\n",
    "Dataset2=save(path2)\n",
    "Labels2=np.zeros(Dataset2.shape[0])+1 # Labels for other images: class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LFDRrjKnMbU5"
   },
   "outputs": [],
   "source": [
    "#Reading other coins images from file system\n",
    "Dataset2=save(path4) \n",
    "Labels2=np.zeros(Dataset2.shape[0])+1  # Labels for other images: class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WVqE5x99bZhL"
   },
   "outputs": [],
   "source": [
    "DatasetComplete=np.vstack((Dataset1,Dataset2)) #Joining Roman coins and other coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IZ1Ad3vAbZhs"
   },
   "outputs": [],
   "source": [
    "LabelsComplete=np.hstack((Labels1,Labels2)) #Joining labels of Roman coins and other coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jhp2ocRrbZiN"
   },
   "outputs": [],
   "source": [
    "#Spliting dataset using StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "for train_index, test_index in skf.split(DatasetComplete, LabelsComplete):\n",
    "    X_train, X_test = DatasetComplete[train_index], DatasetComplete[test_index]\n",
    "    y_train, y_test = LabelsComplete[train_index], LabelsComplete[test_index]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 588011,
     "status": "ok",
     "timestamp": 1545236129534,
     "user": {
      "displayName": "Manuel Ruiz",
      "photoUrl": "",
      "userId": "18393208488880897713"
     },
     "user_tz": -60
    },
    "id": "CN8f_mG-bZj8",
    "outputId": "ec400762-d058-4025-802b-11c4f0af2659"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 124, 124, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 64)        204864    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 1, 32)          51232     \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                1650      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 352,632\n",
      "Trainable params: 352,632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Defining the network and printing the architecture\n",
    "def build_network():\n",
    "  number_of_classes=2\n",
    "  n_inputs=128\n",
    "\n",
    "  input_shape = (n_inputs, n_inputs,3)\n",
    "\n",
    "  # The model is declared\n",
    "  model = Sequential() #Input size 128\n",
    "  #First convolutional layer\n",
    "  model.add(Conv2D(32, kernel_size=(5, 5),activation='relu',input_shape=input_shape)) #Output size 124\n",
    "  #First maxpooling layer\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2))) #Output size 62\n",
    "  #Second convolutional layer\n",
    "  model.add(Conv2D(64, kernel_size=(3, 3),activation='relu')) #Output size 60\n",
    "  #Second maxpooling layer\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2))) #Output size 30\n",
    "  #Third convolutional layer\n",
    "  model.add(Conv2D(128, kernel_size=(3, 3),activation='relu')) #Output size 28\n",
    "  #Third maxpooling layer\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2))) #Output size 14\n",
    "  #Fourth convolutional layer\n",
    "  model.add(Conv2D(64, kernel_size=(5, 5),activation='relu')) #Output size 10\n",
    "  #Fourth maxpooling layer\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2))) #Output size 5\n",
    "  #Fifth convolutional layer\n",
    "  model.add(Conv2D(32, kernel_size=(5, 5),activation='relu')) #Output size 1\n",
    "  #Full conented layers\n",
    "  #Global maxpooling layer\n",
    "  model.add(GlobalMaxPooling2D())\n",
    "  #Dense layer \n",
    "  model.add(Dense(50, activation='relu'))\n",
    "  #Output dense layer\n",
    "  model.add(Dense(2, activation='sigmoid'))\n",
    "  model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['acc'])\n",
    "  return model\n",
    "\n",
    "coins_conv_model=build_network()\n",
    "\n",
    "# A summary of the model is printed\n",
    "print(coins_conv_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1389929,
     "status": "ok",
     "timestamp": 1545237085404,
     "user": {
      "displayName": "Manuel Ruiz",
      "photoUrl": "",
      "userId": "18393208488880897713"
     },
     "user_tz": -60
    },
    "id": "HUium2dAinB5",
    "outputId": "c82b96d5-2e81-4329-9c03-e222d9ed420b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2104/2104 [==============================] - 96s 45ms/step - loss: 0.2542 - acc: 0.9254\n",
      "Epoch 2/10\n",
      "2104/2104 [==============================] - 95s 45ms/step - loss: 0.1872 - acc: 0.9316\n",
      "Epoch 3/10\n",
      "2104/2104 [==============================] - 95s 45ms/step - loss: 0.1408 - acc: 0.9382\n",
      "Epoch 4/10\n",
      "2104/2104 [==============================] - 97s 46ms/step - loss: 0.1220 - acc: 0.9529\n",
      "Epoch 5/10\n",
      "2104/2104 [==============================] - 98s 46ms/step - loss: 0.0964 - acc: 0.9639\n",
      "Epoch 6/10\n",
      "2104/2104 [==============================] - 95s 45ms/step - loss: 0.0810 - acc: 0.9708\n",
      "Epoch 7/10\n",
      "2104/2104 [==============================] - 95s 45ms/step - loss: 0.0567 - acc: 0.9793\n",
      "Epoch 8/10\n",
      "2104/2104 [==============================] - 95s 45ms/step - loss: 0.0449 - acc: 0.9827\n",
      "Epoch 9/10\n",
      "2104/2104 [==============================] - 95s 45ms/step - loss: 0.0398 - acc: 0.9846\n",
      "Epoch 10/10\n",
      "2104/2104 [==============================] - 95s 45ms/step - loss: 0.0298 - acc: 0.9888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efe79cf0cf8>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the CNN using train data\n",
    "y_train_one_hot=to_categorical(y_train)\n",
    "coins_conv_model.fit(X_train, y_train_one_hot,epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aOa9wUSuiBqg"
   },
   "outputs": [],
   "source": [
    " #Making predictions, outputs are probabilities for each image for belong class 0 or class 1\n",
    "  preds = coins_conv_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PQa1knSBOF79"
   },
   "outputs": [],
   "source": [
    "#Class assigment according to the probabilities for each image for belong class 0 or class 1\n",
    "prediction=np.zeros(preds.shape[0])\n",
    "\n",
    "for i in range(0,preds.shape[0]):\n",
    "  if(preds[i][0]<preds[i][1]):\n",
    "    prediction[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q02vkHp9s8u1"
   },
   "outputs": [],
   "source": [
    "#Evaluating the model\n",
    "Accuracy = metrics.accuracy_score(y_test, prediction) #Computing accuracy score\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, prediction) #Computing roc_curve\n",
    "AUC = metrics.auc(fpr, tpr) #Computing auc score\n",
    "F1=metrics.f1_score(y_test, prediction) #Computing f1 score\n",
    "CM = metrics.confusion_matrix(y_test, prediction) #Computing confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1309855,
     "status": "ok",
     "timestamp": 1545237094213,
     "user": {
      "displayName": "Manuel Ruiz",
      "photoUrl": "",
      "userId": "18393208488880897713"
     },
     "user_tz": -60
    },
    "id": "aGFh2iBu8iyM",
    "outputId": "08286b54-b294-4f26-a075-828060793b08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9714285714285714\n",
      "AUC score:  0.8302658486707568\n",
      "F1 score:  0.9848024316109423\n",
      "Confusion matrix: \n",
      " [[ 24  12]\n",
      " [  3 486]]\n"
     ]
    }
   ],
   "source": [
    "#Printing metrics\n",
    "print(\"Accuracy: \", Accuracy)\n",
    "print(\"AUC score: \", AUC)\n",
    "print(\"F1 score: \", F1)\n",
    "print(\"Confusion matrix: \\n\",CM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7XS5tqCYjVoT"
   },
   "source": [
    "#Second Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "auRkHzLT9_Kj"
   },
   "outputs": [],
   "source": [
    "#Function that join all the images in a single directory\n",
    "def join(path,path1,path2):\n",
    "  files1 = os.listdir(path1)\n",
    "  files1 = [file for file in files1 if file.endswith(\".png\")]\n",
    "  files2 = os.listdir(path2)\n",
    "  files2 = [file for file in files2 if file.endswith(\".png\")]\n",
    "  os.mkdir(path)\n",
    "  for i, file in enumerate(files1):\n",
    "    shutil.copy(path1+file,path)\n",
    "  for i, file in enumerate(files2):\n",
    "    shutil.copy(path2+file,path)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Ao60IxTjiph"
   },
   "outputs": [],
   "source": [
    "#Function that read all the images form the join directory\n",
    "def read_all(path):\n",
    "  #Load, normalize and reshape\n",
    "    files = os.listdir(path)\n",
    "    files = [file for file in files if file.endswith(\".png\")]\n",
    "    y = np.zeros(2629)+1\n",
    "    X = []\n",
    "    for i, file in enumerate(files):\n",
    "        if file.startswith(\"class\"):\n",
    "            y[i]=0\n",
    "    \t#print \"Adding file {}/{}\".format(i,len(files))\n",
    "        img = cv2.imread(path+file, -1)\n",
    "\n",
    "        # Convert grayscale to RGB\n",
    "        if len(img.shape) == 2:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Resize to desired size and normalize\n",
    "        img = cv2.resize(img,(imageSize,imageSize))\n",
    "        img = img.astype(float)/255.\n",
    "        X.append(img)\n",
    "    \n",
    "    \n",
    "    # Convert to numpy array\n",
    "    X = np.array(X)\n",
    "    return X , y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jdj9LT6mj13d"
   },
   "outputs": [],
   "source": [
    "#Joining datasets from drive\n",
    "join(\"Dataset\",path1,path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cDaanUzRj6xY"
   },
   "outputs": [],
   "source": [
    "#Joining datasets from file sytem\n",
    "join(\"Dataset\",path3,path4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k5WaJnGakAyK"
   },
   "outputs": [],
   "source": [
    "#For use the join function again delete firts the Dataset dir running this cell\n",
    "shutil.rmtree(\"Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uRL8lsgdkJud"
   },
   "outputs": [],
   "source": [
    "#Reading all images from folder that have the join dataset\n",
    "DatasetC,LabelsC=read_all(\"Dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i0yMTXtZk8fZ"
   },
   "outputs": [],
   "source": [
    "# Splitting dataset in Train and Test dataset folders using StratifiedKFold \n",
    "# and splitting Train and Test dataset folders into Roman coins folder and Other coins folder\n",
    "\n",
    "path_all=\"Dataset/\"\n",
    "splits=5\n",
    "skf = StratifiedKFold(n_splits=splits)\n",
    "j=1\n",
    "files = os.listdir(path_all)\n",
    "files = [file for file in files if file.endswith(\".png\")]\n",
    "\n",
    "for train_index, test_index in skf.split(DatasetC, LabelsC):\n",
    "  path_test=\"Test\"+str(j) #Creating path for test set\n",
    "  path_train=\"Train\"+str(j) #Creating path for train set\n",
    "  os.mkdir(path_test)\n",
    "  os.mkdir(path_test+\"/Roman\") #Creating path for test roman coins\n",
    "  os.mkdir(path_test+\"/Others\") #Creating path for test others coins\n",
    "  os.mkdir(path_train)\n",
    "  os.mkdir(path_train+\"/Roman\") #Creating path for train roman coins\n",
    "  os.mkdir(path_train+\"/Others\") #Creating path for train others coins\n",
    "  \n",
    "  #Copying images from join dataset folder to train and test datset folders\n",
    "  for i, file in enumerate(files):\n",
    "    for k in range(0,train_index.shape[0]):\n",
    "      if train_index[k]==i:\n",
    "        if file.startswith(\"class\"):\n",
    "          shutil.copy(path_all+file,path_train+\"/Roman\")\n",
    "        else:\n",
    "          shutil.copy(path_all+file,path_train+\"/Others\")\n",
    "    for k in range(0,test_index.shape[0]):\n",
    "      if test_index[k]==i:\n",
    "        if file.startswith(\"class\"):\n",
    "          shutil.copy(path_all+file,path_test+\"/Roman\")\n",
    "        else:\n",
    "          shutil.copy(path_all+file,path_test+\"/Others\")\n",
    "  j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xiikl5iS3vSk"
   },
   "outputs": [],
   "source": [
    "#For splitting again the dataset in folders delete train and tes datasets\n",
    "for i in range(1,6):\n",
    "  path_train=\"Train\"+str(i)\n",
    "  path_test=\"Test\"+str(i)\n",
    "  shutil.rmtree(path_train)\n",
    "  shutil.rmtree(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1pTtKTxMQONN"
   },
   "outputs": [],
   "source": [
    "# Directories for our training, and test splits\n",
    "train_dir ='Train5'\n",
    "test_dir = 'Test5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MEVN-mnMRoME"
   },
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "def augmentation(path):\n",
    "  roman_path=path+\"/Roman/\"\n",
    "  other_path=path+\"/Others/\"\n",
    "  \n",
    "  roman_files = os.listdir(roman_path)\n",
    "  roman_files = [file for file in roman_files if file.endswith(\".png\")]\n",
    "  \n",
    "  #Flipping and Rotating train roman coins\n",
    "  for i, file in enumerate(roman_files):\n",
    "    img = cv2.imread(roman_path+file,-1)\n",
    "    rflip = cv2.flip(img,1) #Flipping horizontaly\n",
    "    vflip = cv2.flip(img,0) #Flipping verticaly\n",
    "    rotated = imutils.rotate_bound(img, 90) #Rotating images\n",
    "    #Saving augmented images\n",
    "    cv2.imwrite(roman_path+file[:-4]+\"_90.png\",rotated)\n",
    "    cv2.imwrite(roman_path+file[:-4]+\"_r.png\",rflip)\n",
    "    cv2.imwrite(roman_path+file[:-4]+\"_v.png\",vflip)\n",
    "  \n",
    "  other_files = os.listdir(other_path)\n",
    "  other_files = [file for file in other_files if file.endswith(\".png\")]\n",
    "  \n",
    "  #Flipping and Rotating train other coins\n",
    "  for i, file in enumerate(other_files):\n",
    "    img = cv2.imread(other_path+file,-1)\n",
    "    rflip = cv2.flip(img,1) #Flipping horizontaly\n",
    "    vflip = cv2.flip(img,0) #Flipping verticaly\n",
    "    rotated = imutils.rotate_bound(img, 90) #Rotating images\n",
    "    #Saving augmented images\n",
    "    cv2.imwrite(other_path+file[:-4]+\"_90.png\",rotated)\n",
    "    cv2.imwrite(other_path+file[:-4]+\"_r.png\",rflip)\n",
    "    cv2.imwrite(other_path+file[:-4]+\"_v.png\",vflip)\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LGpiF3FxcN2l"
   },
   "outputs": [],
   "source": [
    "#Applying data augmentation on train dataset\n",
    "augmentation(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SY-t11aYYFmg"
   },
   "outputs": [],
   "source": [
    "#Reading roman coins augmented train dataset and creating labels\n",
    "X_train_Roman=save(train_dir+\"/Roman/\")\n",
    "y_train_Roman=np.zeros(X_train_Roman.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sf8WW3-IqyAo"
   },
   "outputs": [],
   "source": [
    "#Reading other coins augmented train dataset and creating labels\n",
    "X_train_Others=save(train_dir+\"/Others/\")\n",
    "y_train_Others=np.zeros(X_train_Others.shape[0])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_BtCCZ2Uq4Pp"
   },
   "outputs": [],
   "source": [
    "#Joining roman coins and other coins train datasets and labels\n",
    "X_train2=np.vstack((X_train_Roman,X_train_Others))\n",
    "y_train2=np.hstack((y_train_Roman,y_train_Others))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fNg_SylErAm_"
   },
   "outputs": [],
   "source": [
    "#Reading roman coins test dataset and creating labels\n",
    "X_test_Roman=save(test_dir+\"/Roman/\")\n",
    "y_test_Roman=np.zeros(X_test_Roman.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mIRi43HIrE52"
   },
   "outputs": [],
   "source": [
    "#Reading other coins test dataset and creating labels\n",
    "X_test_Others=save(test_dir+\"/Others/\")\n",
    "y_test_Others=np.zeros(X_test_Others.shape[0])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UsHpbny7rKnD"
   },
   "outputs": [],
   "source": [
    "#Joining roman coins and other coins test datasets and labels\n",
    "X_test2=np.vstack((X_test_Roman,X_test_Others))\n",
    "y_test2=np.hstack((y_test_Roman,y_test_Others))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 920,
     "status": "ok",
     "timestamp": 1545835463859,
     "user": {
      "displayName": "Manuel Ruiz",
      "photoUrl": "",
      "userId": "18393208488880897713"
     },
     "user_tz": -60
    },
    "id": "ruDgmz5CmA3E",
    "outputId": "d112d766-2859-4f7d-8890-63fa342726b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 124, 124, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 64)        204864    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 1, 32)          51232     \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                1650      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 352,632\n",
      "Trainable params: 352,632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Defining the network and printing the architecture\n",
    "def build_network():\n",
    "  number_of_classes=2\n",
    "  n_inputs=128\n",
    "\n",
    "  input_shape = (n_inputs, n_inputs,3)\n",
    "\n",
    "  # The model is declared\n",
    "  model = Sequential() #Input size 128\n",
    "  #First convolutional layer\n",
    "  model.add(Conv2D(32, kernel_size=(5, 5),activation='relu',input_shape=input_shape)) #Output size 124\n",
    "  #First maxpooling layer\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2))) #Output size 62\n",
    "  #Second convolutional layer\n",
    "  model.add(Conv2D(64, kernel_size=(3, 3),activation='relu')) #Output size 60\n",
    "  #Second maxpooling layer\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2))) #Output size 30\n",
    "  #Third convolutional layer\n",
    "  model.add(Conv2D(128, kernel_size=(3, 3),activation='relu')) #Output size 28\n",
    "  #Third maxpooling layer\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2))) #Output size 14\n",
    "  #Fourth convolutional layer\n",
    "  model.add(Conv2D(64, kernel_size=(5, 5),activation='relu')) #Output size 10\n",
    "  #Fourth maxpooling layer\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2))) #Output size 5\n",
    "  #Fifth convolutional layer\n",
    "  model.add(Conv2D(32, kernel_size=(5, 5),activation='relu')) #Output size 1\n",
    "  #Full conented layers\n",
    "  #Global maxpooling layer\n",
    "  model.add(GlobalMaxPooling2D())\n",
    "  #Dense layer \n",
    "  model.add(Dense(50, activation='relu'))\n",
    "  #Output dense layer\n",
    "  model.add(Dense(2, activation='sigmoid'))\n",
    "  model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['acc'])\n",
    "  return model\n",
    "\n",
    "coins_conv_model=build_network()\n",
    "\n",
    "# A summary of the model is printed\n",
    "print(coins_conv_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4081770,
     "status": "ok",
     "timestamp": 1545839551161,
     "user": {
      "displayName": "Manuel Ruiz",
      "photoUrl": "",
      "userId": "18393208488880897713"
     },
     "user_tz": -60
    },
    "id": "aZToLWZPoivP",
    "outputId": "31189239-3d93-4600-f759-fbe78d2ca124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8416/8416 [==============================] - 413s 49ms/step - loss: 0.1818 - acc: 0.9333\n",
      "Epoch 2/10\n",
      "8416/8416 [==============================] - 410s 49ms/step - loss: 0.1236 - acc: 0.9558\n",
      "Epoch 3/10\n",
      "8416/8416 [==============================] - 407s 48ms/step - loss: 0.1042 - acc: 0.9648\n",
      "Epoch 4/10\n",
      "8416/8416 [==============================] - 407s 48ms/step - loss: 0.0714 - acc: 0.9742\n",
      "Epoch 5/10\n",
      "8416/8416 [==============================] - 409s 49ms/step - loss: 0.0607 - acc: 0.9783\n",
      "Epoch 6/10\n",
      "8416/8416 [==============================] - 408s 48ms/step - loss: 0.0569 - acc: 0.9815\n",
      "Epoch 7/10\n",
      "8416/8416 [==============================] - 408s 49ms/step - loss: 0.0301 - acc: 0.9902\n",
      "Epoch 8/10\n",
      "8416/8416 [==============================] - 406s 48ms/step - loss: 0.0248 - acc: 0.9911\n",
      "Epoch 9/10\n",
      "8416/8416 [==============================] - 406s 48ms/step - loss: 0.0258 - acc: 0.9931\n",
      "Epoch 10/10\n",
      "8416/8416 [==============================] - 406s 48ms/step - loss: 0.0249 - acc: 0.9913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd9fb0b1cc0>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the CNN using train data\n",
    "y_train_one_hot2=to_categorical(y_train2)\n",
    "coins_conv_model.fit(X_train2, y_train_one_hot2,epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jd5TEca99O8K"
   },
   "outputs": [],
   "source": [
    "#Making predictions, outputs are probabilities for each image for belong class 0 or class 1\n",
    "predictions=coins_conv_model.predict(X_test2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FLKxPkOEluOB"
   },
   "outputs": [],
   "source": [
    "#Class assigment according to the probabilities for each image for belong class 0 or class 1\n",
    "predicted=np.zeros(predictions.shape[0])\n",
    "\n",
    "for i in range(predictions.shape[0]):\n",
    "  if predictions[i][0]<predictions[i][1]:\n",
    "    predicted[i]=1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4eRTnUaz63TD"
   },
   "outputs": [],
   "source": [
    "#Evaluating the model\n",
    "Accuracy = metrics.accuracy_score(y_test2, predicted) #Computing accuracy score\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test2, predicted) #Computing roc_curve\n",
    "AUC = metrics.auc(fpr, tpr) #Computing auc score\n",
    "F1=metrics.f1_score(y_test2, predicted) #Computing f1 score\n",
    "CM = metrics.confusion_matrix(y_test2, predicted) #Computing confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 629,
     "status": "ok",
     "timestamp": 1545839696966,
     "user": {
      "displayName": "Manuel Ruiz",
      "photoUrl": "",
      "userId": "18393208488880897713"
     },
     "user_tz": -60
    },
    "id": "PAfJpp6x_DC4",
    "outputId": "b55e1bb3-9c6f-4f80-afee-96378e3bc115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9942857142857143\n",
      "AUC score:  0.9711997273346967\n",
      "F1 score:  0.9969356486210418\n",
      "Confusion matrix: \n",
      " [[ 34   2]\n",
      " [  1 488]]\n"
     ]
    }
   ],
   "source": [
    "#Printing metrics\n",
    "print(\"Accuracy: \", Accuracy)\n",
    "print(\"AUC score: \", AUC)\n",
    "print(\"F1 score: \", F1)\n",
    "print(\"Confusion matrix: \\n\",CM)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project3.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
